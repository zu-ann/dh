{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 ms, sys: 16.9 ms, total: 47 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names = ['filename', 'title', 'year', 'author', 'years_of_life',\n",
    "         'time_summary', 'time_book', 'name', 'username', 'tradition_country']\n",
    "df = pd.read_csv('metatable.tsv', sep='\\t', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 3.51 ms, total: 14.1 ms\n",
      "Wall time: 14.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "split_tradition_country = df['tradition_country'].str.split('->')\n",
    "df['tradition']= split_tradition_country.str.get(0).apply(lambda x: x.replace('\\xad', ''))\n",
    "df['country']=split_tradition_country.str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 ms, sys: 5.32 ms, total: 32.7 ms\n",
      "Wall time: 40.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "split_years_of_life = df['years_of_life'].str.split('–')\n",
    "df['year_of_birth'] = pd.to_numeric(split_years_of_life.str.get(0), errors='coerce')\n",
    "df['year_of_death'] = pd.to_numeric(split_years_of_life.str.get(1), errors='coerce')\n",
    "df['epoch'] = df[['year_of_birth', 'year_of_death']].mean(axis=1) // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 752 ms, total: 3.85 s\n",
      "Wall time: 8.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text'] = ''\n",
    "for i in df.index:\n",
    "    with open(df.loc[i, 'filename'], 'r', encoding='utf-8') as f:\n",
    "        df.loc[i, 'text'] = f.read().replace('\\xa0', ' ').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "punctuation = set(punctuation + '«»—–…“”\\n\\t' + digits)\n",
    "TABLE = str.maketrans({ch: ' ' for ch in punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_tokenized'] = df.apply(lambda r: tokenize_text(r['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'COM': 'ADJ', 'APRO': 'DET', 'PART': 'PART', 'PR': 'ADP', 'ADV': 'ADV', 'INTJ': 'INTJ',\n",
    "           'S': 'NOUN', 'V': 'VERB', 'CONJ': 'SCONJ', 'UNKN': 'X', 'ANUM': 'ADJ', 'NUM': 'NUM',\n",
    "           'NONLEX': 'X', 'SPRO': 'PRON', 'ADVPRO': 'ADV', 'A': 'ADJ'}\n",
    "pymystem = Mystem()\n",
    "\n",
    "def pymystem_lemmatize_text(pymystem, text, mapping):\n",
    "    lemmas = []\n",
    "    lemmas_pos = []\n",
    "    ana = pymystem.analyze(text.translate(TABLE))\n",
    "    \n",
    "    for word in ana:\n",
    "        if word.get('analysis') and len(word.get('analysis')) > 0:\n",
    "            lemma = word['analysis'][0]['lex'].lower().strip()\n",
    "            \n",
    "            if lemma not in STOPWORDS:\n",
    "                lemmas.append(lemma)\n",
    "                \n",
    "                pos = word['analysis'][0]['gr'].split(',')[0]\n",
    "                pos = pos.split('=')[0].strip()\n",
    "                if pos in mapping:\n",
    "                    lemmas_pos.append(lemma + '_' + mapping[pos]) # здесь мы конвертируем тэги\n",
    "                else:\n",
    "                    lemmas_pos.append(lemma + '_X') # на случай, если попадется тэг, которого нет в маппинге\n",
    "    \n",
    "    return lemmas, lemmas_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 s, sys: 533 ms, total: 39.5 s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = df.apply(lambda r: pymystem_lemmatize_text(pymystem, r['text'], mapping), axis=1).values\n",
    "df_res = pd.DataFrame(list(res), columns = ['text_pymystem_list', 'text_pymystem_pos_list'])\n",
    "df = df.join(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 1.03 s, total: 4.02 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.to_pickle('metatable_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_dataframe(df, col_to_groupby, first_arg, *args):\n",
    "    grouped = df.groupby([col_to_groupby])\n",
    "    \n",
    "    def func(data):\n",
    "        if isinstance(data.iloc[0], str):\n",
    "            return ' '.join\n",
    "        elif isinstance(data.iloc[0], list):\n",
    "            return sum\n",
    "    \n",
    "    df_res = grouped[first_arg].agg(func(df[first_arg])).reset_index()\n",
    "    for arg in args:\n",
    "        df_res[arg] = grouped[arg].agg(func(df[arg])).reset_index()[arg]\n",
    "        \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 516 ms, total: 31.4 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# без колонки text (Memory Error)\n",
    "\n",
    "traditions = get_grouped_dataframe(df, 'tradition',\n",
    "                                   'text_tokenized',\n",
    "                                   'text_pymystem_list',\n",
    "                                   'text_pymystem_pos_list')\n",
    "traditions.to_pickle('traditions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 693 ms, total: 12.2 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "countries = get_grouped_dataframe(df, 'country', 'text',\n",
    "                                  'text_tokenized', \n",
    "                                  'text_pymystem_list',\n",
    "                                  'text_pymystem_pos_list')\n",
    "countries.to_pickle('countries.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 685 ms, sys: 148 ms, total: 833 ms\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "traditions_topic_modeling = df.groupby(['tradition'])['text_pymystem_list'].apply(list).reset_index()\n",
    "traditions_topic_modeling.to_pickle('traditions_topic_modeling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 15.7 ms, total: 375 ms\n",
      "Wall time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grouped_by_authors = df.groupby(['author']).count()\n",
    "needed_authors_list = grouped_by_authors.iloc[np.where(grouped_by_authors['text'] > 5)].index\n",
    "needed_authors_grouped = df[df['author'].isin(needed_authors_list)].groupby(['author'])\n",
    "needed_authors = needed_authors_grouped['text_pymystem_list'].apply(list).reset_index()\n",
    "\n",
    "needed_authors.to_pickle('authors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data for stylo\n",
    "\n",
    "grouped = df.groupby(['name'])\n",
    "needed_names_list = grouped.count().iloc[np.where(grouped['text_pymystem_list'].agg(sum).agg(len) >= 20000)].index\n",
    "needed_names_grouped = df[df['name'].isin(needed_names_list)].groupby(['name'])\n",
    "test = needed_names_grouped['text_pymystem_list'].apply(sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Д. А. Карельский    30229\n",
       "М. Л. Гаспаров      28589\n",
       "Name: text_pymystem_list, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_names_grouped['text_pymystem_list'].apply(sum).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in test.index:\n",
    "    \n",
    "    l = test.loc[j, 'text_pymystem_list']\n",
    "    lst = [test.loc[j, 'text_pymystem_list'][i : i + 10000] for i in range(0, len(l) - (len(l) % 10000) , 10000)]\n",
    "\n",
    "    for i, k in enumerate(lst):\n",
    "        with open(os.getcwd() + '/corpus/_{}.txt'.format(test.loc[j, 'name'], i), 'w', encoding='utf-8') as f:\n",
    "             f.write(' '.join(k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
