{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 21 ms, total: 36 ms\n",
      "Wall time: 58.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names = ['filename', 'title', 'year', 'author', 'years_of_life',\n",
    "         'time_summary', 'time_book', 'name', 'username', 'tradition_country']\n",
    "df = pd.read_csv('metatable.tsv', sep='\\t', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 22 µs, total: 12 ms\n",
      "Wall time: 11.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "split_tradition_country = df['tradition_country'].str.split('->')\n",
    "df['tradition']= split_tradition_country.str.get(0).apply(lambda x: x.replace('\\xad', ''))\n",
    "df['country']=split_tradition_country.str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 728 ms, total: 3.59 s\n",
      "Wall time: 5.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text'] = ''\n",
    "for i in df.index:\n",
    "    with open(df.loc[i, 'filename'], 'r', encoding='utf-8') as f:\n",
    "        df.loc[i, 'text'] = f.read().replace('\\xa0', ' ').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "punctuation = set(punctuation + '«»—–…“”\\n\\t' + digits)\n",
    "TABLE = str.maketrans({ch: ' ' for ch in punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_tokenized'] = df.apply(lambda r: tokenize_text(r['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy = MorphAnalyzer()\n",
    "\n",
    "def pymorphy_lemmatize_text(pymorphy, text_tokenized):\n",
    "    lemmas = []\n",
    "    lemmas_pos = []\n",
    "    for word in text_tokenized:\n",
    "        ana = pymorphy.parse(word.translate(TABLE))[0]\n",
    "        \n",
    "        if ana.normal_form not in STOPWORDS:\n",
    "            if ana.normal_form and ana.tag.POS:\n",
    "                lemmas_pos.append(ana.normal_form + '_' + ana.tag.POS)\n",
    "            lemmas.append(ana.normal_form)\n",
    "    \n",
    "    return lemmas, lemmas_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# res = df.apply(lambda r: pymorphy_lemmatize_text(pymorphy, r['text_tokenized']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df['text_pymorphy_list'] = np.nan\n",
    "# df['text_pymorphy_pos_list'] = np.nan\n",
    "\n",
    "# for i, elem in enumerate(res):\n",
    "#     df['text_pymorphy_list'][i] = elem[0]\n",
    "#     df['text_pymorphy_pos_list'][i] = elem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_pymorphy'] = df.apply(lambda r: ' '.join(r['text_pymorphy_list']), axis=1).values\n",
    "# df['text_pymorphy_pos'] = df.apply(lambda r: ' '.join(r['text_pymorphy_pos_list']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'COM': 'ADJ', 'APRO': 'DET', 'PART': 'PART', 'PR': 'ADP', 'ADV': 'ADV', 'INTJ': 'INTJ',\n",
    "           'S': 'NOUN', 'V': 'VERB', 'CONJ': 'SCONJ', 'UNKN': 'X', 'ANUM': 'ADJ', 'NUM': 'NUM',\n",
    "           'NONLEX': 'X', 'SPRO': 'PRON', 'ADVPRO': 'ADV', 'A': 'ADJ'}\n",
    "pymystem = Mystem()\n",
    "\n",
    "def pymystem_lemmatize_text(pymystem, text, mapping, pos=False):\n",
    "    if pos:\n",
    "        lemmas = []\n",
    "        ana = pymystem.analyze(text.translate(TABLE))\n",
    "        for word in ana:\n",
    "            if len(word['analysis']) > 0:\n",
    "                lemma = word['analysis'][0]['lex'].lower().strip()\n",
    "                if lemma not in STOPWORDS:\n",
    "                    pos = word['analysis'][0]['gr'].split(',')[0]\n",
    "                    pos = pos.split('=')[0].strip()\n",
    "                    if pos in mapping:\n",
    "                        lemmas.append(lemma + '_' + mapping[pos]) # здесь мы конвертируем тэги\n",
    "                    else:\n",
    "                        lemmas.append(lemma + '_X') # на случай, если попадется тэг, которого нет в маппинге\n",
    "    else:\n",
    "        text = re.sub(' +', ' ', text.translate(TABLE))\n",
    "        lemmas = pymystem.lemmatize(text)\n",
    "        lemmas = list(filter(lambda a: a != ' ' and a != ' \\n', lemmas))\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 718 ms, total: 25.3 s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text_pymystem_list'] = df.apply(lambda r: pymystem_lemmatize_text(pymystem,\n",
    "                                                                 r['text'], mapping,\n",
    "                                                                 pos=False), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_pymystem'] = df.apply(lambda r: ' '.join(r['text_pymystem_list']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пока не используется из-за ошибки 'Cannot allocate memory'\n",
    "\n",
    "# df['text_pymystem_pos'] = df.apply(lambda r: pymystem_lemmatize_text(pymystem,\n",
    "#                                                                  r['text'].translate(table), mapping,\n",
    "#                                                                  pos=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 s, sys: 1.99 s, total: 4.35 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.to_pickle('metatable_preprocessed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
